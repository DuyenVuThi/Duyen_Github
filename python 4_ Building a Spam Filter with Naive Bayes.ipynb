{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49152a1e",
   "metadata": {},
   "source": [
    "## Task \n",
    "Building a spam filter for SMS messages\n",
    "\n",
    "### Data source:\n",
    "We'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection).\n",
    "The data collection process is described in more details on [this page](https://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the authors' papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2e3ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sms= pd.read_table(\"SMSSpamCollection\", header=None, names=['label', 'SMS']) ## df has no header row, put SMS to avoid word sms in the message\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04688219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                     SMS\n",
      "count   5572                    5572\n",
      "unique     2                    5169\n",
      "top      ham  Sorry, I'll call later\n",
      "freq    4825                      30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore data\n",
    "print(sms.describe())\n",
    "sms['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30209ed0",
   "metadata": {},
   "source": [
    "To test the spam filter, we're first going to split our dataset into two categories:\n",
    "\n",
    "* A training set, which we'll use to \"train\" the computer how to classify messages.\n",
    "* A test set, which we'll use to test how good the spam filter is with classifying new messages.\n",
    "\n",
    "We're going to keep 80% of our dataset for training, and 20% for testing (we want to train the algorithm on as much data as possible, but we also want to have enough test data). The dataset has 5,572 messages, which means that:\n",
    "\n",
    "* The training set will have 4,458 messages (about 80% of the dataset).\n",
    "* The test set will have 1,114 messages (about 20% of the dataset).\n",
    "\n",
    "For this project, our goal is to create a spam filter that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f431242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize dataset\n",
    "sms_random=sms.sample(frac=1, random_state=1) #frac=1 to randomize entire dataset\n",
    "separate_index=round(len(sms)*0.8)\n",
    "training_set=sms_random[:separate_index].reset_index(drop=True) # drop=True to drop old index column of original dataset\n",
    "test_set=sms_random[separate_index:].reset_index(drop=True)\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e45803c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: label, dtype: float64\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(training_set['label'].value_counts(normalize=True))\n",
    "print(test_set['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffee843",
   "metadata": {},
   "source": [
    " the percentage of spam and ham in both the training and the test set are quite close with the original dataset. It looks good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c1282",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "### Letter Case and Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68487ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32cb4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_10068/1184129949.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  training_set['SMS']= training_set['SMS'].str.replace('\\W',' ').str.lower() # replace by space\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all character aren't words\n",
    "training_set['SMS']= training_set['SMS'].str.replace('\\W',' ').str.lower() # replace by space\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6e3976",
   "metadata": {},
   "source": [
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter. The Naive Bayes algorithm will need to know the probability values of the two equations below to be able to classify the new messages.\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam) \\\\\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "Within the above formula are the sub functions P(wi|Spam) and P(wi|Ham). To calculate these we need to use the below: \n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}} \\\\\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "Some of the terms in the four equations above will have the same value for every new message. As a start, let's first calculate:\n",
    "* P(Spam): the probability that a message is spam   \n",
    "* P(Ham): the probability that a message is not spam\n",
    "* N_Spam: the number of words in all the spam messages\n",
    "* N_Ham: the number of words in all the non-spam messages\n",
    "* N_Vocabulary: the number of words in our vocabulary\n",
    "* Alpha (the partial infinity sign as seen in the denominator): a constant value, usually 1, added to every probability to prevents zero values from making everything zero through multiplication. Known as laplace smoothing/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bffba9",
   "metadata": {},
   "source": [
    "## Create vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61399f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                                SMS\n",
      "0   ham                  [yep, by, the, pretty, sculpture]\n",
      "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
      "2   ham                    [welp, apparently, he, retired]\n",
      "3   ham                                           [havent]\n",
      "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...\n"
     ]
    }
   ],
   "source": [
    "training_set['SMS']=training_set['SMS'].str.split()\n",
    "print(training_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f593f849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yep', 'by', 'the', 'pretty', 'sculpture']\n",
      "7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nor can use like that:\\n    vocabulary = []\\nfor sms in training_set['SMS']:\\n    for word in sms:\\n        vocabulary.append(word)\\n        \\nvocabulary = list(set(vocabulary)) # set create set with distinct word\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary=[]\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        if word in vocabulary:\n",
    "            continue\n",
    "        else:\n",
    "            vocabulary.append(word)\n",
    "print(vocabulary[:5])\n",
    "n_vocabulary= len(vocabulary)\n",
    "print(n_vocabulary)\n",
    "\n",
    "'''\n",
    "or can use like that:\n",
    "    vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary)) # set create set with distinct word\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "180418e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yep  by  the  pretty  sculpture  yes  princess  are  you  going  ...  \\\n",
      "0    1   1    1       1          1    0         0    0    0      0  ...   \n",
      "1    0   0    0       0          0    1         1    1    1      1  ...   \n",
      "2    0   0    0       0          0    0         0    0    0      0  ...   \n",
      "3    0   0    0       0          0    0         0    0    0      0  ...   \n",
      "4    0   0    0       0          0    0         0    0    0      0  ...   \n",
      "\n",
      "   beauty  hides  secrets  n8  jewelry  related  trade  arul  bx526  wherre  \n",
      "0       0      0        0   0        0        0      0     0      0       0  \n",
      "1       0      0        0   0        0        0      0     0      0       0  \n",
      "2       0      0        0   0        0        0      0     0      0       0  \n",
      "3       0      0        0   0        0        0      0     0      0       0  \n",
      "4       0      0        0   0        0        0      0     0      0       0  \n",
      "\n",
      "[5 rows x 7783 columns]\n"
     ]
    }
   ],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary} # each unique word has value length as trainning_set\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index]+=1 # [word] first as it is key, then follow by [index] is index of [0.0.0  ..0] to determine position of +1\n",
    "\n",
    "word_counts=pd.DataFrame(word_counts_per_sms)\n",
    "print(word_counts.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596f9ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS  yep  by  the  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]    1   1    1   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...    0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]    0   0    0   \n",
       "3   ham                                           [havent]    0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0   \n",
       "\n",
       "   pretty  sculpture  yes  princess  are  ...  beauty  hides  secrets  n8  \\\n",
       "0       1          1    0         0    0  ...       0      0        0   0   \n",
       "1       0          0    1         1    1  ...       0      0        0   0   \n",
       "2       0          0    0         0    0  ...       0      0        0   0   \n",
       "3       0          0    0         0    0  ...       0      0        0   0   \n",
       "4       0          0    0         0    0  ...       0      0        0   0   \n",
       "\n",
       "   jewelry  related  trade  arul  bx526  wherre  \n",
       "0        0        0      0     0      0       0  \n",
       "1        0        0      0     0      0       0  \n",
       "2        0        0      0     0      0       0  \n",
       "3        0        0      0     0      0       0  \n",
       "4        0        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_training=pd.concat([training_set, word_counts], axis=1)\n",
    "new_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b742f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_spam:  0.13458950201884254\n",
      "P_ham:  0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "p_spam=new_training['label'].value_counts(normalize=True)[1]\n",
    "p_ham=new_training['label'].value_counts(normalize=True)[0]\n",
    "print(\"P_spam: \",p_spam)\n",
    "print(\"P_ham: \", p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62947e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15190\n",
      "57237\n"
     ]
    }
   ],
   "source": [
    "spam=new_training[new_training['label']=='spam']\n",
    "ham=new_training[new_training['label']=='ham']\n",
    "N_spam=0\n",
    "for message in spam['SMS']:\n",
    "    N_spam += len(message)\n",
    "\n",
    "N_ham=ham['SMS'].apply(len).sum()\n",
    "print(N_spam)\n",
    "print(N_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debcbe8",
   "metadata": {},
   "source": [
    "## Calculating Parameters\n",
    "The key detail here is that calculating P(\"secret\"|Spam) only depends on the training set, and as long as we don't make changes to the training set, P(\"secret\"|Spam) stays constant. The same reasoning also applies to P(\"secret\"|Ham).\n",
    "so P('wi\"|spam) is unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bda51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameter_spam={unique_word:[0] for unique_word in vocabulary}\n",
    "parameter_ham={unique_word:[0] for unique_word in vocabulary}\n",
    "alpha=1\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam=spam[word].sum()\n",
    "    p_word_given_spam=(n_word_given_spam+alpha)/(N_spam+ alpha*n_vocabulary)\n",
    "    parameter_spam[word]=p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham=ham[word].sum()\n",
    "    p_word_given_ham=(n_word_given_ham+alpha)/(N_ham+ alpha*n_vocabulary)\n",
    "    parameter_ham[word]=p_word_given_ham\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b91f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            p_spam_given_message *= parameter_spam[word]\n",
    "            p_ham_given_message *= parameter_ham[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'equal proabilities, have a human classify this!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676d0750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                SMS predict\n",
       "0   ham          Later i guess. I needa do mcat study too.     ham\n",
       "1   ham             But i haf enuff space got like 4 mb...     ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...    spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...     ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...     ham"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predict']=test_set['SMS'].apply(classify)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a921cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "Name: bollean, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     0.987433\n",
       "False    0.012567\n",
       "Name: bollean, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['bollean']=test_set['predict']==test_set['label']\n",
    "print(test_set['bollean'].head())\n",
    "test_set['bollean'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27140811",
   "metadata": {},
   "source": [
    "The filter had an accuracy of 99.87% on the test set, which is an excellent result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e49e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
